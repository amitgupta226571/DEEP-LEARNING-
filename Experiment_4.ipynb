{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amitgupta226571/DEEP-LEARNING-/blob/main/Experiment_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "bf12bd71-7ed9-4769-9faa-7c43c246bfdd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bf12bd71-7ed9-4769-9faa-7c43c246bfdd",
        "outputId": "f6527c77-2bd3-40ef-b451-be81cc124ceb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder, CIFAR10\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# Device configuration (Use GPU if available)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Hyperparameters (Global)\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 5 # Keep low for demonstration, increase to 10-20 for final results\n",
        "LEARNING_RATE = 0.001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "2362387e-8c20-4f51-b63d-41b4da7d49c0",
      "metadata": {
        "id": "2362387e-8c20-4f51-b63d-41b4da7d49c0"
      },
      "outputs": [],
      "source": [
        "def get_dataloaders(dataset_name):\n",
        "    # Transforms\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((64, 64)), # Standardize size\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n",
        "    if dataset_name == 'CIFAR10':\n",
        "        train_set = CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "        test_set = CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "        num_classes = 10\n",
        "\n",
        "    elif dataset_name == 'CatsDogs':\n",
        "        # Assuming you have downloaded and extracted data to ./data/cats_dogs\n",
        "        # Ensure folder structure is ./data/cats_dogs/class_name/image.jpg\n",
        "        if not os.path.exists('./data/cats_dogs'):\n",
        "            raise FileNotFoundError(\"Please download Cats vs Dogs dataset and place in ./data/cats_dogs\")\n",
        "\n",
        "        full_dataset = ImageFolder(root='./data/cats_dogs', transform=transform)\n",
        "        # Split into train/test\n",
        "        train_size = int(0.8 * len(full_dataset))\n",
        "        test_size = len(full_dataset) - train_size\n",
        "        train_set, test_set = random_split(full_dataset, [train_size, test_size])\n",
        "        num_classes = 2\n",
        "\n",
        "    train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    return train_loader, test_loader, num_classes\n",
        "\n",
        "# Example Usage\n",
        "# train_loader, test_loader, num_classes = get_dataloaders('CIFAR10')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "7eae800b-5385-4914-9825-d168fbd2ec8b",
      "metadata": {
        "id": "7eae800b-5385-4914-9825-d168fbd2ec8b"
      },
      "outputs": [],
      "source": [
        "class CustomCNN(nn.Module):\n",
        "    def __init__(self, num_classes, activation_type='relu', init_type='xavier'):\n",
        "        super(CustomCNN, self).__init__()\n",
        "\n",
        "        self.activation_type = activation_type\n",
        "        self.init_type = init_type\n",
        "\n",
        "        # Define Layers\n",
        "        self.features = nn.Sequential(\n",
        "            # Block 1\n",
        "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            self.get_activation(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            # Block 2\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            self.get_activation(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            # Block 3\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            self.get_activation(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(128 * 8 * 8, 512), # Assuming input 64x64 -> 8x8 spatial\n",
        "            self.get_activation(),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "\n",
        "        # Apply Weight Initialization\n",
        "        self.apply(self.initialize_weights)\n",
        "\n",
        "    def get_activation(self):\n",
        "        if self.activation_type == 'relu':\n",
        "            return nn.ReLU()\n",
        "        elif self.activation_type == 'tanh':\n",
        "            return nn.Tanh()\n",
        "        elif self.activation_type == 'leaky_relu':\n",
        "            return nn.LeakyReLU(0.1)\n",
        "        else:\n",
        "            return nn.ReLU()\n",
        "\n",
        "    def initialize_weights(self, m):\n",
        "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
        "            if self.init_type == 'xavier':\n",
        "                nn.init.xavier_uniform_(m.weight)\n",
        "            elif self.init_type == 'kaiming':\n",
        "                nn.init.kaiming_uniform_(m.weight, nonlinearity='relu')\n",
        "            elif self.init_type == 'random':\n",
        "                nn.init.normal_(m.weight, mean=0.0, std=0.02)\n",
        "\n",
        "            if m.bias is not None:\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "6e27d8c6-b3a4-43b0-bcd0-0575eb9b2191",
      "metadata": {
        "id": "6e27d8c6-b3a4-43b0-bcd0-0575eb9b2191"
      },
      "outputs": [],
      "source": [
        "def train_model(model, train_loader, criterion, optimizer, epochs=5):\n",
        "    model.train()\n",
        "    loss_history = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        epoch_acc = 100 * correct / total\n",
        "        epoch_loss = running_loss / len(train_loader)\n",
        "        loss_history.append(epoch_loss)\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.2f}%\")\n",
        "\n",
        "    return loss_history\n",
        "\n",
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "dfacd86f-02f5-413a-a5c4-b9863d4caf4c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfacd86f-02f5-413a-a5c4-b9863d4caf4c",
        "outputId": "3ac4cdde-b527-4880-ace2-9e0334919c00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:05<00:00, 30.7MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting Experiments for CIFAR10 ---\n",
            "\n",
            "Config: Act=relu, Init=xavier, Optim=sgd\n",
            "Epoch [1/3], Loss: 1.5766, Acc: 43.64%\n",
            "Epoch [2/3], Loss: 1.2368, Acc: 55.54%\n",
            "Epoch [3/3], Loss: 1.1021, Acc: 60.48%\n",
            "Test Accuracy: 64.03%\n",
            "\n",
            "Config: Act=relu, Init=xavier, Optim=adam\n",
            "Epoch [1/3], Loss: 1.6666, Acc: 45.26%\n",
            "Epoch [2/3], Loss: 1.0859, Acc: 61.28%\n",
            "Epoch [3/3], Loss: 0.9349, Acc: 67.19%\n",
            "Test Accuracy: 67.37%\n",
            "\n",
            "Config: Act=relu, Init=xavier, Optim=rmsprop\n",
            "Epoch [1/3], Loss: 2.4562, Acc: 40.30%\n",
            "Epoch [2/3], Loss: 1.1825, Acc: 57.77%\n",
            "Epoch [3/3], Loss: 0.9891, Acc: 64.88%\n",
            "Test Accuracy: 58.00%\n",
            "\n",
            "Config: Act=relu, Init=kaiming, Optim=sgd\n",
            "Epoch [1/3], Loss: 1.5879, Acc: 43.24%\n",
            "Epoch [2/3], Loss: 1.2606, Acc: 54.42%\n",
            "Epoch [3/3], Loss: 1.1410, Acc: 59.14%\n",
            "Test Accuracy: 61.61%\n",
            "\n",
            "Config: Act=relu, Init=kaiming, Optim=adam\n",
            "Epoch [1/3], Loss: 1.6207, Acc: 46.86%\n",
            "Epoch [2/3], Loss: 1.0772, Acc: 61.50%\n",
            "Epoch [3/3], Loss: 0.9220, Acc: 67.52%\n",
            "Test Accuracy: 70.39%\n",
            "\n",
            "Config: Act=relu, Init=kaiming, Optim=rmsprop\n",
            "Epoch [1/3], Loss: 2.7196, Acc: 41.45%\n",
            "Epoch [2/3], Loss: 1.1604, Acc: 58.60%\n",
            "Epoch [3/3], Loss: 0.9589, Acc: 65.91%\n",
            "Test Accuracy: 60.22%\n",
            "\n",
            "Config: Act=relu, Init=random, Optim=sgd\n",
            "Epoch [1/3], Loss: 1.5591, Acc: 43.01%\n",
            "Epoch [2/3], Loss: 1.2549, Acc: 54.91%\n",
            "Epoch [3/3], Loss: 1.1113, Acc: 60.22%\n",
            "Test Accuracy: 65.48%\n",
            "\n",
            "Config: Act=relu, Init=random, Optim=adam\n",
            "Epoch [1/3], Loss: 1.4558, Acc: 47.94%\n",
            "Epoch [2/3], Loss: 1.0556, Acc: 62.23%\n",
            "Epoch [3/3], Loss: 0.8948, Acc: 68.46%\n",
            "Test Accuracy: 67.74%\n",
            "\n",
            "Config: Act=relu, Init=random, Optim=rmsprop\n",
            "Epoch [1/3], Loss: 1.8051, Acc: 43.76%\n",
            "Epoch [2/3], Loss: 1.1251, Acc: 59.94%\n",
            "Epoch [3/3], Loss: 0.9474, Acc: 66.64%\n",
            "Test Accuracy: 54.52%\n",
            "\n",
            "Config: Act=tanh, Init=xavier, Optim=sgd\n",
            "Epoch [1/3], Loss: 1.6295, Acc: 42.61%\n",
            "Epoch [2/3], Loss: 1.3272, Acc: 52.74%\n",
            "Epoch [3/3], Loss: 1.1891, Acc: 57.85%\n",
            "Test Accuracy: 60.78%\n",
            "\n",
            "Config: Act=tanh, Init=xavier, Optim=adam\n",
            "Epoch [1/3], Loss: 1.5138, Acc: 46.84%\n",
            "Epoch [2/3], Loss: 1.2060, Acc: 57.17%\n",
            "Epoch [3/3], Loss: 1.0934, Acc: 61.02%\n",
            "Test Accuracy: 60.38%\n",
            "\n",
            "Config: Act=tanh, Init=xavier, Optim=rmsprop\n",
            "Epoch [1/3], Loss: 1.6616, Acc: 42.60%\n",
            "Epoch [2/3], Loss: 1.3035, Acc: 53.05%\n",
            "Epoch [3/3], Loss: 1.1742, Acc: 58.09%\n",
            "Test Accuracy: 58.14%\n",
            "\n",
            "Config: Act=tanh, Init=kaiming, Optim=sgd\n",
            "Epoch [1/3], Loss: 1.6564, Acc: 41.53%\n",
            "Epoch [2/3], Loss: 1.3582, Acc: 51.61%\n",
            "Epoch [3/3], Loss: 1.2314, Acc: 55.97%\n",
            "Test Accuracy: 59.80%\n",
            "\n",
            "Config: Act=tanh, Init=kaiming, Optim=adam\n",
            "Epoch [1/3], Loss: 1.5369, Acc: 46.01%\n",
            "Epoch [2/3], Loss: 1.2400, Acc: 55.66%\n",
            "Epoch [3/3], Loss: 1.1027, Acc: 60.77%\n",
            "Test Accuracy: 61.85%\n",
            "\n",
            "Config: Act=tanh, Init=kaiming, Optim=rmsprop\n",
            "Epoch [1/3], Loss: 1.6481, Acc: 42.62%\n",
            "Epoch [2/3], Loss: 1.3053, Acc: 53.14%\n",
            "Epoch [3/3], Loss: 1.1710, Acc: 58.20%\n",
            "Test Accuracy: 51.69%\n",
            "\n",
            "Config: Act=tanh, Init=random, Optim=sgd\n",
            "Epoch [1/3], Loss: 1.6791, Acc: 39.61%\n",
            "Epoch [2/3], Loss: 1.4165, Acc: 49.34%\n",
            "Epoch [3/3], Loss: 1.2870, Acc: 54.04%\n",
            "Test Accuracy: 56.83%\n",
            "\n",
            "Config: Act=tanh, Init=random, Optim=adam\n",
            "Epoch [1/3], Loss: 1.4648, Acc: 47.32%\n",
            "Epoch [2/3], Loss: 1.1910, Acc: 57.33%\n",
            "Epoch [3/3], Loss: 1.0807, Acc: 61.67%\n",
            "Test Accuracy: 61.29%\n",
            "\n",
            "Config: Act=tanh, Init=random, Optim=rmsprop\n",
            "Epoch [1/3], Loss: 1.6010, Acc: 42.41%\n",
            "Epoch [2/3], Loss: 1.2911, Acc: 53.65%\n",
            "Epoch [3/3], Loss: 1.1680, Acc: 58.38%\n",
            "Test Accuracy: 48.25%\n",
            "\n",
            "Config: Act=leaky_relu, Init=xavier, Optim=sgd\n",
            "Epoch [1/3], Loss: 1.5644, Acc: 44.69%\n",
            "Epoch [2/3], Loss: 1.2321, Acc: 55.86%\n",
            "Epoch [3/3], Loss: 1.1002, Acc: 60.75%\n",
            "Test Accuracy: 63.50%\n",
            "\n",
            "Config: Act=leaky_relu, Init=xavier, Optim=adam\n",
            "Epoch [1/3], Loss: 1.6299, Acc: 47.24%\n",
            "Epoch [2/3], Loss: 1.0930, Acc: 61.36%\n",
            "Epoch [3/3], Loss: 0.9295, Acc: 67.29%\n",
            "Test Accuracy: 69.66%\n",
            "\n",
            "Config: Act=leaky_relu, Init=xavier, Optim=rmsprop\n",
            "Epoch [1/3], Loss: 3.0463, Acc: 36.99%\n",
            "Epoch [2/3], Loss: 1.2615, Acc: 55.01%\n",
            "Epoch [3/3], Loss: 0.9879, Acc: 65.15%\n",
            "Test Accuracy: 62.24%\n",
            "\n",
            "Config: Act=leaky_relu, Init=kaiming, Optim=sgd\n",
            "Epoch [1/3], Loss: 1.5886, Acc: 43.83%\n",
            "Epoch [2/3], Loss: 1.2672, Acc: 54.49%\n",
            "Epoch [3/3], Loss: 1.1557, Acc: 58.57%\n",
            "Test Accuracy: 62.14%\n",
            "\n",
            "Config: Act=leaky_relu, Init=kaiming, Optim=adam\n",
            "Epoch [1/3], Loss: 1.6656, Acc: 47.68%\n",
            "Epoch [2/3], Loss: 1.1162, Acc: 60.51%\n",
            "Epoch [3/3], Loss: 0.9387, Acc: 66.99%\n",
            "Test Accuracy: 68.04%\n",
            "\n",
            "Config: Act=leaky_relu, Init=kaiming, Optim=rmsprop\n",
            "Epoch [1/3], Loss: 3.3323, Acc: 36.88%\n",
            "Epoch [2/3], Loss: 1.2703, Acc: 54.56%\n",
            "Epoch [3/3], Loss: 0.9985, Acc: 64.78%\n",
            "Test Accuracy: 65.20%\n",
            "\n",
            "Config: Act=leaky_relu, Init=random, Optim=sgd\n",
            "Epoch [1/3], Loss: 1.5426, Acc: 44.08%\n",
            "Epoch [2/3], Loss: 1.2507, Acc: 55.16%\n",
            "Epoch [3/3], Loss: 1.1136, Acc: 60.34%\n",
            "Test Accuracy: 65.11%\n",
            "\n",
            "Config: Act=leaky_relu, Init=random, Optim=adam\n",
            "Epoch [1/3], Loss: 1.4197, Acc: 49.23%\n",
            "Epoch [2/3], Loss: 1.0254, Acc: 63.25%\n",
            "Epoch [3/3], Loss: 0.8471, Acc: 70.10%\n",
            "Test Accuracy: 70.10%\n",
            "\n",
            "Config: Act=leaky_relu, Init=random, Optim=rmsprop\n",
            "Epoch [1/3], Loss: 1.8752, Acc: 42.42%\n",
            "Epoch [2/3], Loss: 1.1621, Acc: 58.65%\n",
            "Epoch [3/3], Loss: 0.9470, Acc: 66.51%\n",
            "Test Accuracy: 63.31%\n",
            "\n",
            "Best CIFAR10 Accuracy: 70.39% with Config: relu_kaiming_adam\n"
          ]
        }
      ],
      "source": [
        "def run_experiments(dataset_name):\n",
        "    train_loader, test_loader, num_classes = get_dataloaders(dataset_name)\n",
        "\n",
        "    # Configurations\n",
        "    activations = ['relu', 'tanh', 'leaky_relu']\n",
        "    initializations = ['xavier', 'kaiming', 'random']\n",
        "    optimizers_list = ['sgd', 'adam', 'rmsprop']\n",
        "\n",
        "    best_acc = 0\n",
        "    best_model = None\n",
        "    best_config = \"\"\n",
        "\n",
        "    # Create directory for weights\n",
        "    os.makedirs(f'weights/{dataset_name}', exist_ok=True)\n",
        "\n",
        "    print(f\"--- Starting Experiments for {dataset_name} ---\")\n",
        "\n",
        "    # NOTE: Running all 27 combinations takes a long time.\n",
        "    # For demonstration, we will loop through one list while keeping others constant\n",
        "    # You should un-comment the nested loops for the full lab requirement.\n",
        "\n",
        "    # Full loop structure:\n",
        "    for act in activations:\n",
        "        for init in initializations:\n",
        "             for opt_name in optimizers_list:\n",
        "                print(f\"\\nConfig: Act={act}, Init={init}, Optim={opt_name}\")\n",
        "\n",
        "                model = CustomCNN(num_classes=num_classes, activation_type=act, init_type=init).to(device)\n",
        "                criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "                if opt_name == 'sgd':\n",
        "                    optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=0.9)\n",
        "                elif opt_name == 'adam':\n",
        "                    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "                elif opt_name == 'rmsprop':\n",
        "                    optimizer = optim.RMSprop(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "                _ = train_model(model, train_loader, criterion, optimizer, epochs=3) # Low epochs for speed\n",
        "                acc = evaluate_model(model, test_loader)\n",
        "\n",
        "                if acc > best_acc:\n",
        "                    best_acc = acc\n",
        "                    best_model = model\n",
        "                    best_config = f\"{act}_{init}_{opt_name}\"\n",
        "                    torch.save(model.state_dict(), f'weights/{dataset_name}/best_model.pth')\n",
        "\n",
        "    print(f\"\\nBest {dataset_name} Accuracy: {best_acc:.2f}% with Config: {best_config}\")\n",
        "    return best_model, num_classes, test_loader\n",
        "\n",
        "# Run for CIFAR-10\n",
        "best_cnn_cifar, num_classes_cifar, test_loader_cifar = run_experiments('CIFAR10')\n",
        "\n",
        "# Run for Cats vs Dogs (Uncomment if data is present)\n",
        "# best_cnn_cats, num_classes_cats, test_loader_cats = run_experiments('CatsDogs')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "731ad2a6-caf5-44e3-a491-fdbef6c0c0aa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "731ad2a6-caf5-44e3-a491-fdbef6c0c0aa",
        "outputId": "0a913afd-6805-4efc-be55-ccdb6b804794"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Fine-tuning ResNet-18 for CIFAR10 ---\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 135MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Loss: 1.2345, Acc: 58.34%\n",
            "Epoch [2/5], Loss: 1.0746, Acc: 63.56%\n",
            "Epoch [3/5], Loss: 1.0504, Acc: 64.28%\n",
            "Epoch [4/5], Loss: 1.0420, Acc: 64.47%\n",
            "Epoch [5/5], Loss: 1.0368, Acc: 64.80%\n",
            "Test Accuracy: 64.68%\n",
            "ResNet18 Accuracy: 64.68%\n"
          ]
        }
      ],
      "source": [
        "from torchvision import models\n",
        "\n",
        "def train_resnet(dataset_name, test_loader, num_classes):\n",
        "    print(f\"\\n--- Fine-tuning ResNet-18 for {dataset_name} ---\")\n",
        "\n",
        "    # Load Pretrained Model\n",
        "    resnet = models.resnet18(weights='IMAGENET1K_V1')\n",
        "\n",
        "    # Freeze initial layers (optional, but good for small datasets)\n",
        "    for param in resnet.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    # Modify the final Fully Connected layer\n",
        "    num_ftrs = resnet.fc.in_features\n",
        "    resnet.fc = nn.Linear(num_ftrs, num_classes)\n",
        "\n",
        "    resnet = resnet.to(device)\n",
        "\n",
        "    # Only optimize the final layer\n",
        "    optimizer = optim.Adam(resnet.fc.parameters(), lr=LEARNING_RATE)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Get dataloaders again\n",
        "    train_loader, _, _ = get_dataloaders(dataset_name)\n",
        "\n",
        "    # Train\n",
        "    train_model(resnet, train_loader, criterion, optimizer, epochs=5)\n",
        "    acc = evaluate_model(resnet, test_loader)\n",
        "\n",
        "    torch.save(resnet.state_dict(), f'weights/{dataset_name}/resnet18_finetuned.pth')\n",
        "    return acc\n",
        "\n",
        "# Compare\n",
        "resnet_acc_cifar = train_resnet('CIFAR10', test_loader_cifar, num_classes_cifar)\n",
        "print(f\"ResNet18 Accuracy: {resnet_acc_cifar:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "e389f45d-26c8-478c-883e-ea58b1a9bf45",
      "metadata": {
        "id": "e389f45d-26c8-478c-883e-ea58b1a9bf45"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:base] *",
      "language": "python",
      "name": "conda-base-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}